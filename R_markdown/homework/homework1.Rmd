---
title: "HOMEWORK #1"
author: '이상민'
date: '_April 2, 2020_'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


```{r}
library(caret)
library(e1071)
library(class)
data("segmentationData")
dt <- segmentationData

ds.tr <- subset(segmentationData, Case == "Train")
ds.ts <- subset(segmentationData, Case == "Test")
```

## Question 1
위의 데이터셋을 이용하여 naiveBayes, KNN, SVM의 accuracy를 비교하시오

 - train/test set은 case 컬럼의 구분을 따른다
 
 - 각 classifier의 parameter 값은 default 값으로 한다
 
## Answer 
### Naive Bayes
```{r}
model <- naiveBayes(Class~., data=ds.tr)
pred <- predict(model, ds.ts, type="class")
acc_NB <- mean(pred == ds.ts$Class)
acc_NB
```

### KNN
```{r}
knn.tr <- ds.tr[, 4:61]
knn.ts <- ds.ts[, 4:61]
cl.tr <- factor(ds.tr[, 3])
cl.ts <- factor(ds.ts[, 3])
pred <- knn(knn.tr, knn.ts, cl.tr, k=3, prob=T)
acc_KNN <- mean(pred == cl.ts)
acc_KNN
```

### SVM
```{r}
model <- svm(Class~., data=ds.tr, type="C-classification")
pred <- predict(model, ds.ts)
acc_SVM <- mean(pred == ds.ts$Class)
acc_SVM
```


## Question 2
위의 데이터셋을 이용하여 naiveBayes, KNN, SVM의 accuracy를 비교하시오

 - 10-fold cross validation으로 accuracy를 비교하시오 (seed=1234)
 
 - 각 classifier의 parameter 값은 default 값으로 한다
 
### Naive Bayes
```{r}
library(cvTools)

k <- 10
set.seed(1234)

folds <- cvFolds(nrow(segmentationData), K=k)
acc <- c()
for (i in 1:k) {
    ts.idx <- folds$which == i
    ds.tr <- segmentationData[-ts.idx, ]
    ds.ts <- segmentationData[ts.idx, ]
    
    model <- naiveBayes(Class~., data=ds.tr)
    pred <- predict(model, ds.ts, type="class")
    acc[i] <- mean(pred==ds.ts$Class)
}

acc_10NB <- mean(acc)
acc_10NB
```

### KNN
```{r}
k <- 10
set.seed(1234)

folds <- cvFolds(nrow(segmentationData), K=k)
acc <- c()
for (i in 1:k) {
    ts.idx <- folds$which == i
    ds.tr <- segmentationData[-ts.idx, 4:61]
    ds.ts <- segmentationData[ts.idx, 4:61]
    cl.tr <- factor(segmentationData[-ts.idx, 3])
    cl.ts <- factor(segmentationData[ts.idx, 3])
    
    pred <- knn(ds.tr, ds.ts, cl.tr, k=3)
    acc[i] <- mean(pred==cl.ts)
}

acc_10KNN <- mean(acc)
acc_10KNN
```

### SVM
```{r}
k <- 10
set.seed(1234)

folds <- cvFolds(nrow(segmentationData), K=k)
acc <- c()
for (i in 1:k) {
    ts.idx <- folds$which == i
    ds.tr <- segmentationData[-ts.idx, ]
    ds.ts <- segmentationData[ts.idx, ]
    model <- svm(Class~., data=ds.tr, type="C-classification")
    
    pred <- predict(model, ds.ts)
    acc[i] <- mean(pred == ds.ts$Class)
}

acc_10SVM <- mean(acc)
acc_10SVM
```

## Graph
```{r}
library(ggplot2)

names <- c("Naive Bayes", "KNN", "SVM", "Naive Bayes 10-fold", "KNN 10-fold", "SVM 10-fold")
value <- c(acc_NB, acc_KNN, acc_SVM, acc_10NB, acc_10KNN, acc_10SVM)
value <- value*100
df <- data.frame(names, value)
df

ggplot(df, aes(x=reorder(names, -value), y=value)) +
    geom_bar(stat="identity", width=0.5,
             fill="darkblue") +
    theme(plot.title = element_text(size=20, face="bold", color="black")) +
    labs(x=" ", y="정확도") +
    coord_cartesian(ylim = c(0, 100))
```

